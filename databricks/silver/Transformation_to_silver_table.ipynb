{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b55b8c7-0fb8-4949-9a7b-d86bbf66d672",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7748577b-4a90-4371-ab1b-c47592e978f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sha2, substring, year, month, dayofmonth, hour, current_timestamp, to_timestamp\n",
    "\n",
    "# 1. Read from Bronze\n",
    "bronze_stream = spark.readStream.table(f\"{catalog}.{bronze_schema}.bronze_clickstream\")\n",
    "\n",
    "# 2. Transformations\n",
    "silver_df = (\n",
    "    bronze_stream\n",
    "        # A. Cast string to timestamp first\n",
    "        .withColumn(\"event_timestamp\", to_timestamp(col(\"event_time\")))\n",
    "        \n",
    "        # B. Set the Watermark (10 min late data allowed)\n",
    "        .withWatermark(\"event_timestamp\", \"10 minutes\")\n",
    "        \n",
    "        # C. Deduplicate on the event_id within the watermark window\n",
    "        .dropDuplicates([\"event_id\", \"event_timestamp\"])\n",
    "        \n",
    "        .select(\n",
    "            sha2(col(\"user_id\"), 256).alias(\"user_id_hashed\"),\n",
    "            sha2(col(\"pii.email\"), 256).alias(\"email_hashed\"),\n",
    "            col(\"event_id\"),\n",
    "            substring(col(\"page_url\"), 2, 1000).alias(\"clean_page_url\"),\n",
    "            col(\"event_type\"),\n",
    "            \"event_timestamp\",\n",
    "            col(\"device.os\").alias(\"os\"),\n",
    "            col(\"device.browser\").alias(\"browser\"),\n",
    "            col(\"geo.city\").alias(\"city\"),\n",
    "            col(\"geo.country\").alias(\"country\"),\n",
    "            \n",
    "            # Use getItem() to avoid \"Field Not Found\" errors\n",
    "            col(\"marketing\").getItem(\"utm_source\").alias(\"utm_source\"),\n",
    "            col(\"marketing\").getItem(\"utm_medium\").alias(\"utm_medium\")\n",
    "        )\n",
    "        .withColumn(\"year\", year(col(\"event_timestamp\")))\n",
    "        .withColumn(\"month\", month(col(\"event_timestamp\")))\n",
    "        .withColumn(\"day\", dayofmonth(col(\"event_timestamp\")))\n",
    "        .withColumn(\"hour\", hour(col(\"event_timestamp\")))\n",
    ")\n",
    "\n",
    "# 3. Write to Silver Table\n",
    "checkpoint_path = f\"/Volumes/{catalog}/{silver_schema}/checkpoints/silver_ingestion\"\n",
    "\n",
    "query = (\n",
    "    silver_df.writeStream\n",
    "        .format(\"delta\")\n",
    "        .outputMode(\"append\")\n",
    "        .option(\"checkpointLocation\", checkpoint_path)\n",
    "        .partitionBy(\"year\", \"month\", \"day\")\n",
    "        .trigger(availableNow=True)\n",
    "        .toTable(f\"{catalog}.{silver_schema}.silver_clickstream\")\n",
    ")\n",
    "\n",
    "query.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Transformation_to_silver_table",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
